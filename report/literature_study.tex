\documentclass[thesis.tex]{subfiles}
\begin{document}

\chapter{Related work}
The different descriptors and their algorithms have been constructed based on different requirements with respect to the use of storage and computations. \cite{heinly2012comparative} has described the overall field of descriptors using these two ``variables'' resulting in the following taxonomy: real value parametrization (high storage and computation), patch-based (high storage and low computation), binarized (low storage and high computation), and binary (low storage and computation). We are mainly interested in the best performance and hence we will focus on the class of real value parametrization descriptors. This class of descriptors was revolutionized by \citet{lowe2004distinctive} who inspired many later descriptors. We will summarize the most successful of these. The descriptors are divided into two categories: gradient-based and higher order descriptors. Since we have chosen the two applications: image correspondence and object detection, we shortly summarize the work within these problems. Finally we look at various performance evaluations of descriptors.

\section{Gradient-based descriptors}
\label{sec:gradientDescriptors}
Gradients of an image are often used to describe the region around interest points, since they describe the changes in intensities in the image plane. The \emph{scale-invariant feature transform} (SIFT) descriptor \cite{lowe2004distinctive} is the most popular descriptor based on this approach. It works by dividing the image regions around interest points into square cells and constructing a histogram of gradient orientations for the pixels in each cell. The interest points are detected using a multi-scale DoG detector. By computing the gradient orientations at detection scale, the descriptor becomes scale invariant. The descriptor is also rotation invariant as the cell grid is rotated according to the dominating gradient orientation. Finally the descriptor achieves illumination invariance by normalizing the histograms. \citet{van2010evaluating} extended the SIFT descriptor into the \emph{Opponent SIFT} descriptor, which computes and concatenates the SIFT descriptor in each of the three channels of the opponent color space.

PCA-SIFT \cite{ke2004pca} is also based on combining oriented gradients within a region, but instead of dividing the feature into cell histograms it uses \emph{principal component analysis} (PCA) to reduce the dimensionality of the combined gradients. It also uses a multi-scale DoG detector for interest point detection. PCA computes the most significant linearly independent dimensions of a dataset, and discards the rest. This means that while SIFT is a general purpose descriptor, PCA-SIFT must first be trained on specific data. In order to obtain good results a large and diverse training dataset of images is required. The size of a PCA-SIFT descriptor is substantially lower than SIFT and the other following gradient-based descriptors.

The \emph{gradient location and orientation histogram} (GLOH) descriptor \cite{mikolajczyk2005performance} is a different extension of the SIFT descriptor. It differs from SIFT by using a log-polar grid of ring segment cells instead of a grid of rectangular cells. The dimensionality of the descriptor is like PCA-SIFT also reduced using PCA, but the analysis is performed on the gradient orientation histograms instead rather than the raw gradients.

The DAISY descriptor \cite{tola2008fast} is a descriptor originally developed for dense wide-baseline matching, and it is therefore developed to create a descriptor of each pixel in an image very efficiently. The descriptor is created from Gaussian directional derivative convolutions of the image, computed at points located in a circular grid resembling a daisy. The directional derivatives are similar to the histogram bins of SIFT, but can be computed much faster. Further refinements of the algorithm and experiments with the actual layout of the daisy formation have been examined by \citet{winder2009picking}, who claim that the DAISY descriptor performs better than SIFT when applied to the image correspondence problem.

The \emph{Histograms of Oriented Gradient} (HOG) descriptor is another alternative to SIFT proposed by \citet{dalal2005histograms} for the purpose of pedestrian detection. Rather than using a detector, a sliding window approach is used for searching an image for pedestrians. For each window one HOG descriptor is constructed and a binary classification of the descriptor is performed. The window is divided into a grid of cells, in which histograms of oriented gradients are computed. Adjacent cells are then grouped together into blocks, which are normalized to accommodate for local illumination changes. The final HOG descriptor is a concatenation of the histograms of the window cells. Parts models using the HOG descriptor have been developed \cite{felzenszwalb2008discriminatively} in order to improve upon the accuracy of object detection.

\section{Higher order differential descriptors}

Another approach to descriptor design is to use higher order differential information. We use the term \emph{local $k$-jet} to refer to a vector consisting of the derivatives up to order $k$ at some point.

\citet{crosier2010using} base their texture representation, which is just a descriptor but used for textures, on the local $2$-jet. They partition the jet space into six Basic Image Features (BIFs) and compute these across a region of pixels at four different scales. The chosen BIFs are distinct texture elements such as dark spots and bright lines. Rather than computing the distribution of BIFs at each scale, the four BIFs at each point are combined into a BIF-column, and a histogram over all possible BIF-columns is computed. The descriptors are used for texture classification.

\citet{larsen2012jet} have had success using local 4-jets. Their $\mathcal{J}_4$-grid2 descriptor is computed from local 4-jets at four points spread out across a pixel region. A whitening process is used on the jet coefficients to scale normalize and decorrelate the descriptors, allowing for Euclidean distance as a distance measure. The descriptor was evaluated against state of the art on the image correspondence problem and performed favourably, despite the simplicity of the descriptor.

Another recent higher order descriptor is the galaxy descriptor from \citet{pedersen2013shape}, which is used to predict star-formation rate from galaxy texture. The descriptor consists of multi-scale histograms of gradient orientation as well as shape index, which is a simple 1D representation of second order differential information. The histograms are computed over a single region at eight scale levels.
%
\section{Image correspondence}
%
The image correspondence problem has been frequently used throughout the literature for testing invariants and robustness of descriptors (\cite{lowe2004distinctive,mikolajczyk2005performance,ke2004pca,larsen2012jet,cui2009scale,toews2009sift} e.g.). This is due to the simplicity of the problem: Take two images of the same scene with a pre-defined transformation, and find correspondences between the two images. The problem can be solved by searching for similar descriptors across the two images. By comparing these matches against a ground truth, we can measure the descriptor's ability to create robust descriptors under transformations. In practice the image correspondence problem can be used for baseline stereo matching, where correspondences are found with the goal of creating a 3D reconstruction of a scene. \citet{tola2008fast} solve this problem by developing and using the DAISY descriptor. We will however not go further into this problem but instead use the basis image correspondence problem for descriptor evaluation.

\citet{mikolajczyk2005performance} test 10 descriptors including SIFT, GLOH, and PCA-SIFT by solving the image correspondence problem. Two descriptors are classified as a match by some matching strategy based on the distance between them. The result depends on a threshold $t$, which is varied to obtain a performance curve. Matching regions having an overlap error below $0.5$ under the given image transformation (a homography) are classified as correct matches. A curve showing the $recall$ as a function of the $1-precision$ is used as performance measure. Three different matching strategies were tested, which we describe in detail in \Cref{sec:matching_strategies}. \citet{mikolajczyk2005performance} conclude that GLOH performs best, closely followed by SIFT, and that SIFT obtains best results by matching based on nearest neighbour distance ratio.

\citet{dahl2011finding} test the SIFT and DAISY descriptors with 7 state of the art detectors to find the best detector-descriptor combination. This is done by having a dataset with various image transformations and known 3D geometry, and hence having a known ground truth for patch correspondences. Compared to \citet{mikolajczyk2005performance}, the dataset is substantially larger and more varied, which suggests that their results are more generalized. For this study only the nearest neighbour distance ratio is used as matching strategy. The Receiver Operating Characteristics (ROC) curve is computed for varying ratio-thresholds and finally the area under the curve (AUC) is computed. The average AUC over all the scenes of the dataset is used as performance measure. The ROC and its AUC are described further in \Cref{sec:performance_measures}. \citet{dahl2011finding} conclude that SIFT and DAISY perform best when being paired with DoG or MSER detectors.
%
\section{Object detection}
%
Object detection has been conducted in various ways and complexities throughout the literature. Since we are interested in comparing our descriptor performance against state of the art descriptors, we will not be developing a complex object detection system, but rather stay with a simple one for which we can change the descriptor. Therefore we limit this part of our literature study to simple object detection algorithms. As mentioned in \Cref{sec:gradientDescriptors} the HOG descriptor \cite{dalal2005histograms} was developed for pedestrian detection using a binary classification of windows across the image. An SVM is trained on the raw HOG descriptors and used for determining the outcome of the binary classification. \citet{felzenszwalb2008discriminatively} improved this approach by expanding the HOG algorithm with a parts-model

Image classification problems are however commonly solved by using the bag-of-visual-words (BoVW) strategy such as \citet{csurka2004visual} do with their \emph{Bags of Keypoints} for visual categorization. The BoVW strategy's training step is called codebook generation. First, descriptors are computed for a training set of images. Second, the descriptors are clustered into $k$ cluster centers called the vocabulary. Third, the descriptors are projected to their closest match in the vocabulary and a histogram (bag) of words is created for each image. Finally a classifier is trained on the bags-of-visual-words and their corresponding class. Prediction of an image is performed by computing the bags-of-visual-words (like training step 3) for the image and predicting the class using the trained classifier.

Fisher Vectors \cite{sanchez2013image} is an alternative to the BoVW strategy. A Gaussian Mixture Model (GMM) with a diagonal covariance matrix is assumed for the distribution of descriptors of an image. Various statistics of the GMM are computed, from which we compute the Fisher vector signature of each image's descriptors and apply power (signed square-rooting) and $l_2$ normalizations. \citet{sanchez2013image} compares the Fisher vectors against a soft-BoVW \todo{Find reference for soft-BoVW} histogram approach using a linear SVM for training and prediction.

\todo{Make notes into paragraph}
First abstract object detector using SVM: \cite{papageorgiou2000trainable}.
SVM original: \cite{boser1992training}
 
Potential extra Mining article: \cite{fernando2014mining}

\subbibliography

\end{document}
