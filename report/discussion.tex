\documentclass[thesis.tex]{subfiles}
\begin{document}

\chapter{Discussion}

Recall that we have developed the two main descriptors: GO, which uses gradient information similar to SIFT and HOG, and SI, which uses second order information in the form of shape index and curvedness. Furthermore we have combined the two descriptors into a GO+SI descriptor. The descriptors have a large number of parameters, which can be modified to fit the application. We have optimized the parameters for each of the two applications: image correspondence and pedestrian detection. In these applications we compare the final descriptor test results against the SIFT and HOG descriptors respectively.

In this chapter we first discuss our optimal descriptors and the results on each of the two applications. Then we discuss the differences between the applications, and finally we propose and discuss future work.

\section{Image correspondence}
\label{sec:discussionIc}
Recall that the image correspondence evaluation shows that our descriptors are very close performance-wise, and marginally outperform SIFT. The difference is larger for light variations and statistically significant with 95\% confidence in a few cases.

However these results rely on the assumption that the PR AUCs are normally distributed for each position as described in \Cref{sec:icResults}. This assumption might not hold since the PR AUCs are bounded between 0 and 1, and hence the tails will be heavily clipped when the mean is close to either bound.

With the test results in mind, we now compare and reflect on the different design choices of SIFT and our descriptor.

Where SIFT uses vector normalization and clipping for illumination invariance and robustness, we use pixel-wise normalization and normalization of the final vector. The choice of using local illumination estimation and normalization is most likely the reason for the difference in performance under light variations.

Another difference between SIFT and our descriptor is that we don't support rotation estimation. The DTU dataset images have fixed orientation and hence we have omitted this step from SIFT too in order to avoid a decreased performance due to wrong rotation estimation. We have verified that including this step indeed reduces performance. The rotation estimation of SIFT could easily be adopted by our descriptor as an initial step for rotation invariance. Our cell layouts would then be rotated according to the estimated orientation.

The cell layouts of SIFT and our descriptors differ greatly. Our descriptors are based on polar grids such as GLOH and DAISY, whereas SIFT uses a square grid. Assuming that structure close to the interest point is more important than structure further away, we see two advantages of our grids. The corner cells of SIFT are further away than the other edge cells, while our cells in each ring have equal distance to the interest point. The SIFT grid contains more outer-cells than inner-cells, while our rings have have an equal amount of cells. This gives an even distribution of cells in both angular and radial direction. According to \citet{cui2009scale} polar grids are more robust against scale estimation errors and hence this should apply to our descriptors as well. Furthermore we believe that our grids are be more robust against rotation estimation errors, since the cell areas would overlap more with the correctly rotated grid than for a squared grid. This will however need to be tested before coming to a conclusion.

We see that we have more cells and bins than SIFT resulting in a descriptor with larger dimensionality than SIFT. This is related to the fact that our descriptor cells are spread across a larger area, and thus the amount of samples in each cell histogram is closer to that of SIFT than the dimensionality suggests.

Our initial idea was to base our cell histograms on locally orderless images \cite{koenderink1999structure}. This work is based on Gaussian kernels for bin and cell aperture functions rather than the triangle kernels of SIFT. Our parameter study has shown that the two kernels produce almost identical results, but the triangle kernels are less expensive to compute in practice. This is due to the complexity of the Gaussian kernels and their infinite support, which we limit to 3$\beta$, while the simple triangle kernels only have $2\beta$ support (see \Cref{sec:apertureKernelFunctions}).

The center aperture function, which SIFT likewise uses, only has a minor influence on the performance of our descriptor. Our performance gain from this function is most likely not as high as for SIFT, since our cell layouts already favour the structure closer to the interest point.

From our test results we see that the addition of SI to GO only increases performance marginally. The addition however adds a substantial number of dimensions to the descriptor.
Given the tiny performance increase we recommend using the GO descriptor on its own.

\section{Pedestrian detection}
\label{sec:discussionOd}
In the pedestrian detection application, our optimal parameters yield a very high dimensionality compared to HOG. We therefore introduced the compact GO+SI descriptor, which is constructed from picking slightly worse parameters than the optimal in order to achieve a lower dimensionality than HOG.

Our pedestrian detection evaluation shows that our descriptors are not as good as HOG, with our compact GO+SI descriptor right behind. SI does not work well on its own, but adding it to both GO and HOG increases performance.

A big difference between our descriptors and HOG is in the strategy of local normalization. An advantage of HOG's block normalization is that each cell contains four different normalization factors for different directions away from the cell. This information is different from the histogram bins, because it is based on relative magnitudes rather than orientations. An advantage of our pixel-wise normalization is that the normalization region is defined per pixel instead of per block. This allows for pixels inside a cell to be normalized individually, where HOG normalizes them equally. Interestingly, our optimal normalization region for GO defined by a Gaussian window with $\eta = 4$ is similar in size to the four overlapping $8 \times 8$ pixel block normalizations from HOG.

Another difference between GO and HOG is that HOG computes both undirected and directed gradients. The undirected gradients are subject to a more strict thresholding than the directed gradients, and hence redundancy is avoided in some cases. Under the assumption that we use a linear SVM and due to the fact that we don't use thresholding, the simple solution of summing opposite bins to get undirected gradient information would not increase the descriptive power of our descriptors.

Looking at \Cref{tbl:INRIAparams}, we both have a larger density and cell overlap compared to HOG. This results in a large number of cells that are slightly larger than HOG's. Assuming a fixed number of cells, increasing the overlap between cells is a trade-off between two factors: specific gradient information will be spread out to multiple cells, increasing the robustness to small changes in pedestrian postures. However, this also reduces the influence of the information to each cell. This causes the classification ability of easily recognisable pedestrians to decrease, but a larger range of harder pedestrians to score well. The same reasoning can be said for overlap between histogram bins.

The initial PR AUCs shown in \Cref{tbl:inriaResults} indicate that GO+SI is significantly better than compact GO+SI. Retraining on additional hard negatives removes this performance gap, and compact GO+SI takes a slight lead. Taking the non-optimal parameters into account this is surprising, and shows that we could have included retraining in the parameter study. This would however have greatly increased the run time of the optimization. We can think of two possible reasons that combined explain this effect: Firstly compact GO+SI has much lower dimensionality than GO+SI and therefore each added hard negative has a larger impact on the classifier for compact GO+SI than for GO+SI. Secondly the amount of hard negatives added for retraining of the compact GO+SI classifier is 2.2 times higher than for GO+SI.

The dimensionality and test results of GO+SI and compact GO+SI suggest that GO+SI contains redundant information. The critical difference between the two descriptors is the density of cells and bins. The density causes the dimensionality to supersede the number of pixels for a single descriptor in the scale-space images. Generally we want the descriptors to represent the essential parts of a region and thus be smaller than the raw data. This is the case for compact GO+SI and HOG.

HOG is still superior to compact GO+SI, but if we should recommend one of our descriptors, compact GO+SI would be the one.

\section{Differences between applications}
When starting the project, we had the idea, that we could create a descriptor which generalized well to different applications. However as seen in \Cref{sec:icParameterStudy,sec:odParameterStudy} we need both different design choices and different parameters for the image correspondence and pedestrian detection applications.

First of all we had to construct vastly different cell layouts depending on the use of an interest point detector or a sliding window. Secondly both smoothing of scale-space images and normalization of the final descriptor adds a minor improvement to image correspondence, while greatly decreasing performance for pedestrian detection. Finally most of the optimal parameters for pedestrian detection differ significantly from image correspondence: For example the normalization scale and the overlap between cells is much larger.

Some of the differences can be explained by the difference in the nature of the problems. In image correspondence we try to create distinctive descriptors for each individual feature, whereas in pedestrian detection we try to generalize the class of pedestrians. For example colour information is not a good indicator in pedestrian detection, but it has proven useful for finding image correspondences.

\section{Future work} % rename to alternative approaches?
%
Our pixel-wise normalization scheme, while significantly improving results over no normalization, has the downside of boosting noise in dark areas. An example of this can be seen in \Cref{fig:pixelNormalizationExample}. It may be possible to create a clever scheme to keep the increased robustness to local illumination changes while removing the noise from dark areas.

We decided to resize scale-space images respective to their scales, such that histograms are computed across the same pixel area regardless of detection scale. This means that potentially a lot of information is lost from downsampling the large scale images. It is possible to omit the resizing step and compute histograms at their original scales, but while experimenting with this we quickly ran into time and memory problems. The problem is even medium size features at $\sigma = 8$ multiply the computation time and memory by $8^2 = 64$. Another problem is whether the bin scales should be compensated for changing the number of pixels in histograms. While the approach was infeasible for us to use, there may be ways to overcome these issues.

A possible issue with constructing our shape index histograms is the non-uniformity of the distribution of shape indices in natural images, which is reported in \citep[Fig. 3]{lillholm2009statistics}. This figure shows large peaks at what is equivalent to $S = \pm 1/2$ and very few shape indices around $S = \pm 1$, which is consistent with our own findings, e.g. \Cref{fig:cellHistFigureSiCfeature}. The result of this is that some of the histogram bins have a very little effect on our distance measure. One could investigate ways of adjusting the histograms to be more uniform, possibly by moving the bin positions and scales and/or weighting them differently.

As mentioned in \Cref{sec:icParameterStudy}, our scheme for optimizing parameters risks getting stuck in local optima. We defined our parameters to be as uncorrelated as possible, but it could still be the case that modifying several of the parameters together would give a better result. The initialization of the parameters could likewise give a suboptimal solution. A possible way to improve our parameter optimization, while still being able to evaluate it in a reasonable time frame, is a simulated annealing approach. This is a probabilistic method designed to find approximated global optima in a large search space, by trying nearby random parameter choices with gradually smaller jumps. Another potential improvement to our parameter study could be to optimize the combined GO+SI instead of optimizing GO and SI individually.

There are also many approaches used in the literature that could potentially improve our descriptor. PCA could be used to reduce the dimensionality, allowing for a higher number of cells and bins. Alternatives to the shape index and curvedness as mentioned in \Cref{sec:valueMagnitudeFunctions} could be thoroughly tested as well as higher than second order differential structure for use as bin value and magnitude functions. We could extend our descriptor to represent structure from multiple scales like the galaxy descriptor \Citet{pedersen2013shape}. This is however not necessarily a good idea in combination with omitting smoothing for pedestrian detection, since the information will largely be the same. Two-way matching, where we consider the distance ratio between best matches in both images, could improve image correspondence results. However, it is not important for comparing the performance of descriptors to each other. Higher level descriptors such as bag-of-words, deformable part models \cite{felzenszwalb2008discriminatively}, and Fisher vectors \cite{sanchez2013image} could be used to perform object detection based on distributions of our descriptors rather than the descriptors themselves.

\subbibliography

\end{document}
