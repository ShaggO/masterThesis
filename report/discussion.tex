\documentclass[thesis.tex]{subfiles}
\begin{document}

\chapter{Discussion}

In this chapter we will discuss the optimal results of the work described in our report.
We first discuss the differences in descriptors and their optimal parameters between the two applications. Secondly we compare our descriptors and results with SIFT and HOG individually.
This is followed by a discussion of possible future work. Finally we conclude upon the work we have presented.

\section{Differences between applications}
When starting the project, we had the idea, that we could create a descriptor which generalized well to different applications. However as seen in \Cref{sec:icParameterStudy,sec:odParameterStudy} we need both different design choices and different parameters for the image correspondence and pedestrian detection applications.

First of all we had to construct vastly different cell layouts depending on the use of an interest point detector or a sliding window. Secondly both smoothing of scale-space images and normalization of the final descriptor adds a minor improvement to image correspondence, while greatly decreasing performance for pedestrian detection. Finally most of the optimal parameters for pedestrian detection differ significantly from image correspondence: For example the normalization scale and the overlap between cells is much larger.
		
\section{Comparison with SIFT}
Recall that the image correspondence evaluation showed that our descriptors marginally outperform SIFT. The difference is larger for light variations and statistically significant in a few cases. With these results in mind, we will now compare and reflect on the different design choices of SIFT and our descriptor.

Where SIFT uses vector normalization and clipping for illumination invariance and robustness, we use pixel normalization and normalization of the final vector. The choice of using local illumination estimation and normalization is most likely the reason for the difference in performance under light variations.

Another difference between SIFT and our descriptor is that we don't support rotation estimation. The DTU dataset images have fixed orientation and hence we have omitted this step from SIFT too in order to avoid a decreased performance due to wrong rotation estimation. We have verified that including this step indeed reduces performance. The rotation estimation of SIFT could easily be adopted by our descriptor as an initial step for rotation invariance. Our cell layouts would then be rotated according to the estimated orientation.

The cell layouts of SIFT and our descriptors differ greatly. Our descriptors are based on polar grids such as GLOH and DAISY, whereas SIFT uses a square grid. Assuming that structure close to the interest point is more important than structure further away, we see two advantages of our grids. The corner cells of SIFT are further away than the other edge cells, while our cells in each ring have equal distance to the interest point. The SIFT grid contains more outer-cells than inner-cells, while our rings have have an equal amount of cells. This gives an even distribution of cells in both angular and radial direction. According to \citet{cui2009scale} polar grids are more robust against scale estimation errors and hence this should apply to our descriptors as well. Furthermore we believe that our grids are be more robust against rotation estimation errors, since the cell areas would overlap more with the correctly rotated grid than for a squared grid. This will however need to be tested before coming to a conclusion.

We see that we have more cells and bins than SIFT resulting in a descriptor with larger dimensionality than SIFT. This is related to the fact that our descriptor cells are spread across a larger area, and thus the amount of samples in each cell histogram is closer to that of SIFT than the dimensionality suggests.

Our initial idea was to base our cell histograms on locally orderless images \cite{koenderink1999structure}. This work is based on Gaussian kernels for bin and cell aperture functions rather than the triangle kernels of SIFT. Our parameter study has shown that the two kernels produce almost identical results, but the triangle kernels are less expensive to compute in practice. This is due to the complexity of the Gaussian kernels and their infinite support, which we limit to 3$\beta$, while the simple triangle kernels only have $2\beta$ support (see \Cref{sec:apertureKernelFunctions}).

The center aperture function, which SIFT likewise uses, only has a minor influence on the performance of our descriptor. Our performance gain from this function is most likely not as high as for SIFT, since our cell layouts already favour the structure closer to the interest point.

From our test results we see that the addition of shape index to GO only increases performance marginally. The addition however adds a substantial number of dimensions to the descriptor.
Given the tiny performance increase we recommend using the GO descriptor on its own.

\section{Comparison with HOG}
- overall results
- block normalization vs. pixel normalization
- density/overlap of cells
- RGB maximization
- Compact GoSi (13,5)
- HOG+SI

\section{Future work} % rename to alternative approaches?
%
Our pixel normalization scheme, while significantly improving results over no normalization, has the downside of boosting noise in dark areas. An example of this can be seen in \Cref{fig:pixelNormalizationExample}. It may be possible to create a clever scheme to keep the increased robustness to local illumination changes while removing the noise from dark areas.

We decided to resize scale-space images respective to their scales, such that histograms are computed across the same pixel area regardless of detection scale. This means that potentially a lot of information is lost from downsampling the large scale images. It is possible to omit the resizing step and compute histograms at their original scales, but while experimenting with this we quickly ran into time and memory problems. The problem is even medium size features at $\sigma = 8$ multiply the computation time and memory by $8^2 = 64$. Another problem is whether the bin scales should be compensated for changing the number of pixels in histograms. While the approach was infeasible for us to use, there may be ways to overcome these issues.

A possible issue with constructing our shape index histograms is the non-uniformity of the distribution of shape indices in natural images, which is reported in \citep[Fig. 3]{lillholm2009statistics}. This figure shows large peaks at what is equivalent to $S = \pm 1/2$ and very few shape indices around $S = \pm 1$, which is consistent with our own findings, e.g. \Cref{fig:cellHistFigureSiCfeature}. The result of this is that some of the histogram bins have a very little effect on our distance measure. One could investigate ways of adjusting the histograms to be more uniform, possibly by moving the bin positions and scales and/or weighting them differently.

As mentioned in \Cref{sec:icParameterStudy}, our scheme for optimizing parameters risks getting stuck in local optima. We defined our parameters to be as uncorrelated as possible, but it could still be the case that modifying several of the parameters together would give a better result. The initialization of the parameters could likewise give a suboptimal solution. A possible way to improve our parameter optimization, while still being able to evaluate it in a reasonable time frame, is a simulated annealing approach. This is a probabilistic method designed to find approximated global optima in a large search space, by trying nearby random parameter choices with gradually smaller jumps. 

There are also many approaches used in the literature that could potentially improve our descriptor. PCA could be used to reduce the dimensionality, allowing for a higher number of cells and bins. Alternatives to the shape index and curvedness as mentioned in \Cref{sec:valueMagnitudeFunctions} could be thoroughly tested as well as higher than second order differential structure for use as bin value and magnitude functions. We could extend our descriptor to represent structure from multiple scales like the galaxy descriptor \Citet{pedersen2013shape}. This is however not necessarily a good idea in combination with omitting smoothing for pedestrian detection, since the information will largely be the same. Two-way matching, where we consider the distance ratio between best matches in both images, could improve image correspondence results. However, it is not important for comparing the performance of descriptors to each other. Higher level descriptors such as bag-of-words models or Fisher vectors \cite{sanchez2013image} could be used to perform object detection based on distributions of our descriptors rather than the descriptors themselves.

\section{Conclusion}

\subbibliography

\end{document}
