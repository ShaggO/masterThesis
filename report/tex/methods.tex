\documentclass[../thesis.tex]{subfiles}
\begin{document}

\section{Methods}

\subsection{Detectors}

\subsubsection{Scale invariance}

\subsection{Descriptors}

\subsubsection{SIFT}

Gradients of an image are often used to describe the region around interest points, since they describe the changes in intensities in the image plane.
The \emph{scale-invariant feature transform} (SIFT) descriptor
\cite{lowe2004distinctive} is the most popular descriptor based on this
approach. It works by dividing the image regions surrounding interest
points into square cells and constructing a histogram of gradient
orientations for the pixels in each cell. The interest points are detected
using a multi-scale DoG detector. By computing the gradient orientations
at detection scale, the descriptor becomes scale invariant. The descriptor
is also rotation invariant as the cell grid is rotated according to the
dominating gradient orientation. Finally the descriptor achieves illumination
invariance by normalizing the histograms. The SIFT descriptor uses a grid of
$4 \times 4$ cells each consisting of $4 \times 4$ pixels, with 8 histogram
bins for each cell. This results in a dimensionality of $4 \times 4 \times 8 =
128$.

\subsubsection{PCA-SIFT}

\emph{PCA-SIFT} \cite{ke2004pca} is also based on combining oriented gradients
within a region, but instead of dividing the feature into cell histograms
it uses principal component analysis (PCA) to reduce the dimensionality
of the combined gradients. It also uses a multi-scale DoG detector for
interest point detection as SIFT. When computing PCA we compute the most
significant orthogonal dimensions of a dataset. In order to obtain good
results a large and diverse dataset of images and their features is required.
PCA-SIFT describes a single patch of $41 \times 41$ pixels. When computing
the gradients it gives gradient dimensionality of $2\times39\times39 = 3042$,
which is reduced by PCA to 36 dimensions.

\subsubsection{GLOH}

The \emph{gradient location and orientation histogram} (GLOH) descriptor
\cite{mikolajczyk2005performance} is an extension of the SIFT descriptor.
It differs from the SIFT descriptor by making a log-polar grid of
cells instead of rectangular cells. Furthermore the dimensionality of
the descriptor is reduced using PCA (on 47,000 patches according to
\cite{mikolajczyk2005performance}). The log-polar grid is split into three
rings at radius 6, 11, and 15, of which each of the two outer-most rings are
divided into eight angular cells giving a total of 17 cell bins. The gradient
orientations are divided into 16 bins giving a histogram of $16 \times 17
= 272$ bins. This is reduced to 128 dimensions by using the 128 largest
eigenvectors from PCA on a training dataset.

\subsubsection{DAISY}

The \emph{DAISY} descriptor \cite{tola2008fast} is a descriptor originally
developed for dense wide-baseline matching, and it is therefore developed
to create a descriptor of each pixel in an image very efficiently. The
descriptor is created from Gaussian directional derivative convolutions of
the image in eight directions and at three different scales. The use of these
convolutions allows for fast computations of simple convolutions compared
to the slower binning and post-processing used in SIFT. The descriptor of
each point is a concatenation of the eight directional derivatives of 25
points located in a circular grid shown in a daisy formation as shown in
Figure ??\todo{add daisy figure reference}. This results in a descriptor of
$25 \times 8 = 200$ dimensions. Further refinements of the algorithm and
experiments with the actual layout of the daisy formation have been examined
in \cite{winder2009picking}, in which the DAISY descriptor is claimed to perform
better than SIFT when used on the image correspondence problem.

\subsubsection{HOG}

The \emph{Histograms of Oriented Gradient} (HOG) descriptor is another
alternative to SIFT proposed in \cite{dalal2005histograms} for pedestrian
detection. Contrary to SIFT which is computed individually at specified
interest points, the HOG descriptors are computed in a dense grid over a
detection window and each block descriptor is a part of a larger descriptor
usually trained using an SVM. The Gradients are first computed using simple
1D masks. Secondly magnitude and spatially weighted histograms of the
orientations (0-180$^{\circ}$) of the gradients are computed for spatial
regions named cells\todo{Add note about interpolation of votes}. The cells are
then grouped together into blocks of cells for normalization to accomodate
for local illumination changes. These blocks can either be rectangular with
rectangular cells (R-HOG), or circular using a log-polar partitioning as the
DAISY descriptor. The normalization is performed using either the L2-norm,
a clipped and re-normalized L2-norm, or the square root of the L1-norm for
best performance. HOG descriptors are able to work directly on RGB images
unlike the original SIFT descriptor. This is done by computing the gradients
for each colour channel and choosing the gradient with the highest magnitude
for each pixel. For R-HOG the optimal bin number is found to be 9, optimal
block size $3\times3$ cell blocks and optimal cell size $6\times6$ pixels
with block spacing 8.\todo{Should optimal parameters for C-HOG be mentioned?}
Furthermore parts models using the HOG descriptor have been developed
\cite{felzenszwalb2008discriminatively} in order to improve upon the accuracy
of object detection.

\subsubsection{BIF-columns}

Another approach to descriptor design is to use higher order differential
information.
We use the term \emph{local $k$-jet} to refer to a vector
consisting of differential information up to order $k$ at some point.

\emph{Stability based similarity measure} (SBSM) \cite{balmashnova2008novel} for
matching of higher order differential information descriptors
Crosier and Griffin \cite{crosier2010using} base their texture representation, which
is just a descriptor but used for textures, on the local $2$-jet. They
partition the jet space into 6 Basic Image Features (BIFs) and compute these
across a region of pixels at four different scales. The chosen BIFs are
distinct texture elements such as dark spots and bright lines. Rather than
computing the distribution of BIFs at each scale, the four BIFs at each point
are combined into a BIF-column, and a histogram over all $6^4 = 1296$ possible
BIF-columns is computed. The 1296-dimensional descriptors are used for texture
classification.

\subsubsection{Jet descriptor}

\cite{larsen2012jet} have had success using local 4-jets. Their
$\mathcal{J}_4$-grid2 descriptor is computed from local 4-jets at four points
spread out across a pixel region. A whitening process is used on the jet
coefficients to scale normalize and decorrelate the descriptors, allowing for
Euclidean distance as a distance measure. The descriptor was evaluated against
state of the art on the image correspondence problem and performed favourably,
despite the simplicity of the descriptor.

\subsubsection{Galaxy descriptor}

Another recent higher order descriptor is the galaxy descriptor from Pedersen
et al.\cite{pedersen2013shape}, which is used to predict star-formation
rate from galaxy texture. The descriptor consists of multi-scale histograms
of gradient orientation as well as shape index, which is a simple 1D
representation of second order differential information. The histograms are
computed over a single region at eight scale levels.

\subsection{Matching strategies}
\label{sec:matching_strategies}

Thresholding, best-thresholding, ratio-thresholding.

\subsection{Performance measures}
\label{sec:performance_measures}

ROC, AUC, recall, 1-precision
\emph{Stability based similarity measure} (SBSM) \cite{balmashnova2008novel} for matching of higher order differential information descriptors.


\subsection{Invariants}
When describing interest points and their local regions in real world images we experience a lot of transformations of the actual physical objects. We are however interested in being able to describe the interest point without any of these transformations applied, in which case we have a better chance of recognizing the interest point in other images. In this section we will go through a list of possible transformations that we wish for our descriptor to be invariant to.

\subsubsection{Translation}
The first transformation that we describe is translation. Translation occurs when images are taken from different positions and hence the interest points are translated in the image plane. Translation invariance is often achieved by combining a descriptor with an interest point detector which tells the descriptor where the interest points are located spatially in the image. Another approach is to use a sliding window technique in which a detection window is moved around the image trying to find a suitable matching position as in \cite{felzenszwalb2008discriminatively}. Translation invariance is almost always desired.

\subsubsection{Rotation}
Rotation naturally occurs when either the camera or the object in question is rotated. Like the translation invariance we often get rotation invariance by combining the descriptor with an interest points detector. The detector often estimates the direction of the interest point based on the direction of the gradient in the interest point, and hence it outputs both translation and rotation invariant points to compute descriptors for. Rotation invariance is often desired but not always needed, as in \cite{dalal2005histograms,felzenszwalb2008discriminatively} where only detection of pedestrians in upright positions is needed. More general descriptors such as SIFT are however rotational invariant

\subsubsection{Illumination}
Affine illumination model:
\begin{align*}
  \widetilde{I}(x) &= a I(x)  + b \\
  \frac{\Diff{n} a I(x)}{\Diff x^n} &= a \frac{\Diff{n}I}{ x^n} \\
  S(x,y,\sigma) &= \frac{2}{\pi} \Atan{\frac{-L_{xx} - L_{yy}}{\sqrt{4L_{xy}^2 + (L_{xx} - L_{yy})^2}}} \\
  \widetilde{S}(x,y,\sigma) &= \frac{2}{\pi} \Atan{\frac{-a L_{xx} - a L_{yy}}{\sqrt{4(aL_{xy})^2 + (aL_{xx} - aL_{yy})^2}}} \\
  &= \frac{2}{\pi} \Atan{\frac{a (-L_{xx} - L_{yy})}{\sqrt{a^2 \left(4L_{xy}^2 + \left(L_{xx} - L_{yy} \right)^2 \right)}}} \\
  &= \frac{2}{\pi} \Atan{\frac{-L_{xx} - L_{yy}}{\sqrt{4L_{xy}^2 + \left(L_{xx} - L_{yy} \right)^2}}} \\
\end{align*}


When normalizing k-jet with L2-norm:
\begin{align*}
  \mathcal{J}_k &= \left( \mset{L_{x^n y^m} | 0 < n+m \leq k} \right)^T \\
  \widetilde{\mathcal{J}}_k &=\left( \mset{a L_{x^n y^m} | 0 < n+m \leq k} \right)^T \\
  \left \| \widetilde{\mathcal{J}}_k \right \|_2 &= \sqrt{\sum_{0 < n+m \leq k} (a L_{x^n y^m})^2} \\
      &= \sqrt{a^2\sum_{0 < n+m \leq k} (L_{x^n y^m})^2} \\
      &= a\sqrt{\sum_{0 < n+m \leq k} (L_{x^n y^m})^2} \\
      &= a \left \| \mathcal{J}_k \right \|_2 \\
  \frac{\widetilde{\mathcal{J}}_k}{\left \| \widetilde{\mathcal{J}}_k \right \|_2} &=
      \frac{\mathcal{J}_k}{\left \| \mathcal{J}_k \right \|_2}
\end{align*}

By using a small sigma for calculating the derivatives in the jet, we only use a small spatial area for the calculations which minimizes the risk of crossing a shadow edge. By combining multiple jets or shape indices into histograms we are able to calculate a descriptor across a shadow edge but still maintaining illumination invariance.

\subsubsection{Scale}
Noget med scalespace \cite{griffin1997scale}.

\subsubsection{Perspective}
noget med ?

%\subsection{Sliding window}
%
%\subsection{Spatial pooling schemes}
%
%\subsection{Normalization (local)}
%
%\subsection{Rotational invariance}
%
%\subsection{Histograms}
%
%\subsection{PCA}
%
%\subsection{Gradient orientation}
%
%\subsection{$k$-Jets}
%
%\subsection{Shape index}

\subbibliography

\end{document}
